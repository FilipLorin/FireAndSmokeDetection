{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d10277-d8b0-4980-81ca-1d6892e86a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging in e:\\apps\\anaconda\\envs\\googlecolab\\lib\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in e:\\apps\\anaconda\\envs\\googlecolab\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in e:\\apps\\anaconda\\envs\\googlecolab\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\apps\\anaconda\\envs\\googlecolab\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\apps\\anaconda\\envs\\googlecolab\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\apps\\anaconda\\envs\\googlecolab\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\apps\\anaconda\\envs\\googlecolab\\lib\\site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: colorama in e:\\apps\\anaconda\\envs\\googlecolab\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.6-py3-none-any.whl (51 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.6\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/cookiecacheqq/fasdd-cv?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▌                                                                | 1.61G/11.5G [10:08<1:01:51, 2.86MB/s]"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # API Keys are stored in .env file\n",
    "\n",
    "# Load D-Fire dataset from Google Drive\n",
    "#!pip install gdown\n",
    "import gdown \n",
    "from zipfile import ZipFile\n",
    "df_url = \"https://drive.google.com/uc?id=19LSrZHYQqJSdKgH8Mtlgg7-i-L3eRhbh\"  # smoke = 0, fire = 1\n",
    "df_destination = \"datasets\\\\D-Fire.zip\"\n",
    "df_directory = \"datasets\\\\D-Fire\"\n",
    "\n",
    "if not os.path.isdir(df_directory):\n",
    "    if not os.path.isfile(df_destination):\n",
    "        print(\"Downloading dataset...\", end='\\r')\n",
    "        gdown.download(df_url, df_destination, quiet=False)\n",
    "        print(\"D-Fire dataset downloaded\")\n",
    "    else:\n",
    "        with ZipFile(df_destination, 'r') as zip_ref:\n",
    "            print(\"Unpacking...\" , end=\"\\r\")\n",
    "            zip_ref.extractall(df_directory)\n",
    "            print(\"Files extracted\")\n",
    "\n",
    "# Load FASDD Dataset from Kaggle\n",
    "#!pip install kagglehub\n",
    "import kagglehub\n",
    "fasdd_path = kagglehub.dataset_download(\"cookiecacheqq/fasdd-cv\")\n",
    "\n",
    "# Load datasets from Roboflow\n",
    "#!pip install roboflow\n",
    "from roboflow import Roboflow\n",
    "\n",
    "roboflow_api_key = os.getenv(\"RF_API_KEY\")\n",
    "rf = Roboflow(api_key=roboflow_api_key)\n",
    "\n",
    "# Download roboflow datasets\n",
    "os.chdir(\"datasets\")\n",
    "datasets = [\n",
    "    rf.workspace(\"data2\").project(\"fire-smoke-detection-ua3dm\").version(2), # fire = 0, smoke = 1\n",
    "    rf.workspace(\"brad-dwyer\").project(\"wildfire-smoke\").version(1), # smoke = 0\n",
    "]\n",
    "datasets = [d.download(\"yolov11\") for d in datasets]\n",
    "print(\"Roboflow datasets downloaded\")\n",
    "os.chdir(\"..\")\n",
    "\n",
    "locations = [d.location for d in datasets]\n",
    "\n",
    "# Standardize label indices: SMOKE = 0, FIRE = 1\n",
    "# swap indices in dataset 0\n",
    "import re\n",
    "import builtins\n",
    "\n",
    "count = 0\n",
    "for d in [\"train\", \"valid\", \"test\"]:\n",
    "    in_path = os.path.join(datasets[0].location, d, \"labels\")\n",
    "    out_path = os.path.join(datasets[0].location + \"_corrected_labels\", d, \"labels\")\n",
    "    for f in os.listdir(in_path):\n",
    "        filename = os.fsdecode(f)\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        with builtins.open(os.path.join(in_path, filename), 'r') as file:\n",
    "            o_contents = file.read()\n",
    "        with builtins.open(os.path.join(out_path, filename), 'w') as file:\n",
    "            contents = re.sub(\"0 \", \"2 \", o_contents)\n",
    "            contents = re.sub(\"1 \", \"0 \", contents)\n",
    "            contents = re.sub(\"2 \", \"1 \", contents)\n",
    "            file.write(contents)\n",
    "\n",
    "yaml_data = f\"\"\"\n",
    "path: Combined\n",
    "train: train\\\\images\n",
    "val: valid\\\\images\n",
    "test: test\\\\images\n",
    "\n",
    "nc: 2\n",
    "names: ['smoke', 'fire']\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data.yaml\", 'w') as file:\n",
    "    file.write(yaml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5dac62-9cc6-4af7-92f9-4ad275ce36fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-77e106580c0b9a1e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-77e106580c0b9a1e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start Tensorflow dashboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs/detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a865d-c54c-4c77-b6c1-d98243ca19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained YOLO model for transfer learning\n",
    "#!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Training options\n",
    "opts = {\n",
    "    \"data\": \"data.yaml\",\n",
    "    \"batch\": 256,\n",
    "    \"val\": True,\n",
    "    \"optimizer\": \"auto\",\n",
    "    \"pretrained\": True,\n",
    "    \"freeze\": 11, # transfer learning\n",
    "    \"imgsz\": 224, # larger is better for texture recognition but slow\n",
    "    \"plots\": True,\n",
    "    \"workers\": 1, # fix for old Nvidia GPU\n",
    "}\n",
    "\n",
    "# Train model to establish baseline performance\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "model.train(**opts, epochs=50, name=\"yolo_v11n_224px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475c44ba-9bf9-44ed-9ee9-9a89e916d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load best-fit model\n",
    "model = YOLO(\"runs/detect/yolo_v11n_defaults/weights/best.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c0343-d29b-4fbe-9517-39bb075f63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune model\n",
    "from torch.nn.utils import prune\n",
    "\n",
    "ratio = 0.25\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if \".conv\" in name:\n",
    "        print(f\"Pruning layer {name}...\")\n",
    "        prune.l1_unstructured(module, name='weight', amount=ratio)\n",
    "        prune.remove(module, 'weight')\n",
    "print(\"Pruning done\")\n",
    "\n",
    "# Fine-tune after pruning0\n",
    "model.train(**opts | {\"freeze\": False, \"epochs\":5, \"name\":\"yolo_v11n_pruned\"}) #override optimizer and lr\n",
    "model.save(f'pruned_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bbeb5bb-14b8-48ef-95a1-9f032ef768bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 21.9ms\n",
      "1: 640x640 (no detections), 21.9ms\n",
      "2: 640x640 1 smoke, 21.9ms\n",
      "3: 640x640 1 smoke, 21.9ms\n",
      "4: 640x640 1 smoke, 21.9ms\n",
      "5: 640x640 2 smokes, 6 fires, 21.9ms\n",
      "6: 640x640 (no detections), 21.9ms\n",
      "7: 640x640 2 smokes, 4 fires, 21.9ms\n",
      "8: 640x640 4 fires, 21.9ms\n",
      "9: 640x640 (no detections), 21.9ms\n",
      "Speed: 5.5ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Test on random inputs from dataset\n",
    "import random\n",
    "import os\n",
    "\n",
    "random.seed()\n",
    "num_imgs = 5\n",
    "\n",
    "img_dir = \"datasets/Combined\" + \"/test/images\"\n",
    "random_imgs = [random.choice(os.listdir(img_dir)) for x in range(num_imgs)]\n",
    "results = model.predict([os.path.join(img_dir, im) for im in random_imgs])\n",
    "\n",
    "for result in results:\n",
    "    #boxes = result.boxes\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a968586-1964-4462-bdbd-b35d70ec65f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
